{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from img_loader import DatasetLoader\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.misc\n",
    "from PIL import ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP ONE -> Create a CAM compatible VGG16 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Discovering dataset...\n",
      "DATASET LOADER] \n",
      "2 classes found.\n",
      " 4 images found.\n",
      "DATASET LOADER] Shuffling order...\n",
      "DATASET LOADER] \n",
      "Ready for loading!\n",
      " 3 for training and 1 for testing\n",
      "DATASET LOADER] Loaded all imgs for training. Next call will load test data...\n",
      "DATASET LOADER] Loading completed!\n",
      "(3, 256, 256, 3)\n",
      "(3, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_loader = DatasetLoader('dataset_mini', 10000)\n",
    "_, x_train, y_train = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float64')\n",
    "\n",
    "x_train = preprocess_input(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, dataset_loader.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "CAM (Conv2D)                 (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "W (Dense)                    (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 17,075,522\n",
      "Trainable params: 17,075,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"CAM\", activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(applications.VGG16(weights='imagenet', include_top=False).layers)\n",
    "\n",
    "# last conv for having only one inbound node\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode=\"same\", name=\"CAM\"))\n",
    "model.add(GlobalAveragePooling2D(name=\"GAP\"))\n",
    "model.add(Dense(dataset_loader.nb_classes, activation='softmax', name='W'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "for i in range(0, epochs):\n",
    "    model.fit(x_train, y_train, batch_size=10, epochs=1, verbose=0)\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Loaded all imgs for test. Done! Next call will load train data\n",
      "DATASET LOADER] Loading completed!\n",
      "(1, 256, 256, 3)\n",
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.118095397949219, 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, x_test, y_test = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, dataset_loader.nb_classes)\n",
    "model.evaluate(x_test, y_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP TWO -> Define a k.function like generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process input\n",
    "input_img = x_train[2]\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbound (?, ?, ?, 512)\n"
     ]
    }
   ],
   "source": [
    "#Verify layer output \n",
    "print('inbound', model.get_layer('CAM').output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_outputs_generator(model, layer_name):\n",
    "    \"\"\"\n",
    "    Gets the output generator of a specific layer of the model.\n",
    "\n",
    "    :param model: The model\n",
    "    :param layer_name: The layer's name\n",
    "    :return: the output generator (a function)\n",
    "    \"\"\"\n",
    "    layer_model = Model(\n",
    "        input=model.input,\n",
    "        output=model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "    return layer_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1131915.625          0.        645365.5     ...,   879188.0625\n",
      "          0.             0.     ]\n",
      "  [ 1607605.875          0.       1428295.375   ...,  1454711.125          0.\n",
      "          0.     ]\n",
      "  [ 1754076.375          0.       1645915.      ...,  1651056.125          0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 1620372.375          0.       1638908.125   ...,  1561236.             0.\n",
      "          0.     ]\n",
      "  [ 1306235.75           0.       1511590.5     ...,  1294088.125          0.\n",
      "          0.     ]\n",
      "  [  616004.5625         0.       1140064.625   ...,   723536.4375\n",
      "          0.             0.     ]]\n",
      "\n",
      " [[ 1865530.125          0.       1226240.375   ...,  1411242.875          0.\n",
      "          0.     ]\n",
      "  [ 2561548.25           0.       2615586.25    ...,  2255223.             0.\n",
      "          0.     ]\n",
      "  [ 2771343.75           0.       3005977.75    ...,  2508255.75           0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 2534366.             0.       2933273.25    ...,  2342894.5            0.\n",
      "          0.     ]\n",
      "  [ 2037512.875          0.       2674130.      ...,  1950294.375          0.\n",
      "          0.     ]\n",
      "  [  945144.             0.       1977628.875   ...,  1082070.25           0.\n",
      "          0.     ]]\n",
      "\n",
      " [[ 2126517.             0.       1422762.875   ...,  1595669.25           0.\n",
      "          0.     ]\n",
      "  [ 2895342.5            0.       3002618.75    ...,  2516157.5            0.\n",
      "          0.     ]\n",
      "  [ 3123920.25           0.       3446357.5     ...,  2774423.             0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 2819743.25           0.       3321377.25    ...,  2563813.             0.\n",
      "          0.     ]\n",
      "  [ 2274362.25           0.       3030520.5     ...,  2137040.             0.\n",
      "          0.     ]\n",
      "  [ 1050854.875          0.       2245930.25    ...,  1178141.875          0.\n",
      "          0.     ]]\n",
      "\n",
      " ..., \n",
      " [[ 2280541.75           0.       1482277.625   ...,  1706172.625          0.\n",
      "          0.     ]\n",
      "  [ 3084301.75           0.       3174190.5     ...,  2647038.5            0.\n",
      "          0.     ]\n",
      "  [ 3202599.25           0.       3651341.      ...,  2847328.             0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 2467770.75           0.       2938293.      ...,  2198701.25           0.\n",
      "          0.     ]\n",
      "  [ 1982057.625          0.       2653643.      ...,  1836627.5            0.\n",
      "          0.     ]\n",
      "  [  910285.4375         0.       1984259.375   ...,  1011793.375          0.\n",
      "          0.     ]]\n",
      "\n",
      " [[ 2209235.75           0.       1392686.625   ...,  1577751.875          0.\n",
      "          0.     ]\n",
      "  [ 2912893.             0.       3012914.      ...,  2441259.             0.\n",
      "          0.     ]\n",
      "  [ 2902147.25           0.       3414118.5     ...,  2553517.75           0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 2014785.375          0.       2448379.      ...,  1770438.625          0.\n",
      "          0.     ]\n",
      "  [ 1602287.25           0.       2171715.75    ...,  1465410.625          0.\n",
      "          0.     ]\n",
      "  [  728498.             0.       1604381.375   ...,   801755.125          0.\n",
      "          0.     ]]\n",
      "\n",
      " [[ 1447563.625          0.        851188.6875  ...,   886164.875          0.\n",
      "          0.     ]\n",
      "  [ 1818616.375          0.       1989497.125   ...,  1372713.875          0.\n",
      "          0.     ]\n",
      "  [ 1751945.625          0.       2270790.5     ...,  1423204.75           0.\n",
      "          0.     ]\n",
      "  ..., \n",
      "  [ 1140575.625          0.       1497240.5     ...,   916945.3125\n",
      "          0.             0.     ]\n",
      "  [  892885.25           0.       1297575.125   ...,   755936.3125\n",
      "          0.             0.     ]\n",
      "  [  390787.03125        0.        959306.8125  ...,   425516.25           0.\n",
      "          0.     ]]]\n"
     ]
    }
   ],
   "source": [
    "print(layer_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer output shape (8, 8, 512)\n",
      "image shape (8, 8)\n",
      "number of filters: 512\n"
     ]
    }
   ],
   "source": [
    "#Grab the output of the layer:\n",
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)[0]\n",
    "print('layer output shape',layer_outputs.shape)\n",
    "img = layer_outputs[:, :, 0]\n",
    "print('image shape', img.shape)\n",
    "print('number of filters:', layer_outputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd934b185c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd934b8f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP layer shape (?, 512)\n",
      "layer w shape (2,)\n",
      "layer w shape[0] (512, 2)\n",
      "layer w[0] [[ 0.04337372  0.09135871]\n",
      " [-0.03819891 -0.07878692]\n",
      " [-0.06702378  0.03550604]\n",
      " ..., \n",
      " [-0.09575662 -0.05487208]\n",
      " [ 0.07110356  0.03503336]\n",
      " [ 0.03006226  0.03498405]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So as we see here the weights that we need are as model.get_layer(\"W\").get_weights()[0][k_kernel][class_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reduce_opacity(im, opacity):\n",
    "    \"\"\"\n",
    "    Returns an image with reduced opacity.\n",
    "    Taken from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/362879\n",
    "    \"\"\"\n",
    "    if im.mode != 'RGBA':\n",
    "        im = im.convert('RGBA')\n",
    "    else:\n",
    "        im = im.copy()\n",
    "    alpha = im.split()[3]\n",
    "    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n",
    "    im.putalpha(alpha)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def heatmap_generate(input_img, model, class_to_predict, layer_name, image_name=None):\n",
    "   \n",
    "    output_generator = get_outputs_generator(model, layer_name)\n",
    "    layer_outputs = output_generator(np.expand_dims(input_img, axis=0))[0]\n",
    "    heatmap = Image.new(\"RGBA\", (224, 224), color=0)\n",
    "    # Normalize input on weights\n",
    "    w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "\n",
    "    for z in range(0, layer_outputs.shape[2]): # Iterate through the number of kernels\n",
    "        img = layer_outputs[:, :, z]\n",
    "\n",
    "        deprocessed = scipy.misc.toimage(cv2.resize(img, (224, 224))).convert(\"RGBA\")\n",
    "        deprocessed = reduce_opacity(deprocessed, w[z][class_to_predict])\n",
    "        heatmap.paste(deprocessed, (0, 0), deprocessed)\n",
    "    # heatmap = image.img_to_array(ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\"))\n",
    "    # ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\").save(\"TMP.png\", \"PNG\")\n",
    "    heatmap.save(\"TMP.png\", \"PNG\")\n",
    "    heatmap = cv2.imread(\"TMP.png\", cv2.CV_8UC3)  # FIXME: remove tmp file\n",
    "    \n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    if image_name is not None:\n",
    "        heatmap_colored = cv2.putText(heatmap_colored, image_name, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0),\n",
    "                                      2)\n",
    "    return Image.fromarray(cv2.resize(heatmap_colored, (224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2b33722148db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheatmap_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CAM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-b6902c322181>\u001b[0m in \u001b[0;36mheatmap_generate\u001b[0;34m(input_img, model, class_to_predict, layer_name, image_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdeprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdeprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_opacity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_to_predict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mheatmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# heatmap = image.img_to_array(ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6077476f2370>\u001b[0m in \u001b[0;36mreduce_opacity\u001b[0;34m(im, opacity)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTaken\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0maspn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivestate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mASPN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mCookbook\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mPython\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mRecipe\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m362879\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mopacity\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_img = x_train[2]\n",
    "img = heatmap_generate(input_img, model, 0, 'CAM', image_name='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71410286  0.9110744 ]\n",
      " [ 0.33603132  0.1197679 ]\n",
      " [ 0.20243427  0.651317  ]\n",
      " ..., \n",
      " [ 0.06926379  0.23099005]\n",
      " [ 0.84262466  0.64911866]\n",
      " [ 0.65240717  0.64888936]]\n",
      "[ 0.71410286  0.9110744 ]\n",
      "0.714103\n"
     ]
    }
   ],
   "source": [
    "w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "print(w)\n",
    "print(w[0])\n",
    "print(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04337372,  0.09135871],\n",
       "       [-0.03819891, -0.07878692],\n",
       "       [-0.06702378,  0.03550604],\n",
       "       ..., \n",
       "       [-0.09575662, -0.05487208],\n",
       "       [ 0.07110356,  0.03503336],\n",
       "       [ 0.03006226,  0.03498405]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"W\").get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = np.asarray([[1.1, 3.2, -0.5], [1.1, 3.2, -0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outname = 'cam_test.tiff'\n",
    "Image.fromarray(a).save(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.10000002,  3.20000005, -0.5       ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread(outname, cv2.IMREAD_UNCHANGED)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
