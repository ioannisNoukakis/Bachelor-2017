{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from img_loader import DatasetLoader\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.misc\n",
    "from PIL import ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP ONE -> Create a CAM compatible VGG16 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Discovering dataset...\n",
      "DATASET LOADER] \n",
      "2 classes found.\n",
      " 4 images found.\n",
      "DATASET LOADER] Shuffling order...\n",
      "DATASET LOADER] \n",
      "Ready for loading!\n",
      " 3 for training and 1 for testing\n",
      "DATASET LOADER] Loaded all imgs for training. Next call will load test data...\n",
      "DATASET LOADER] Loading completed!\n",
      "(3, 256, 256, 3)\n",
      "(3, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_loader = DatasetLoader('dataset_mini', 10000)\n",
    "_, x_train, y_train = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float64')\n",
    "\n",
    "x_train = preprocess_input(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, dataset_loader.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "CAM (Conv2D)                 (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "W (Dense)                    (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 17,075,522\n",
      "Trainable params: 17,075,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", name=\"CAM\", activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(applications.VGG16(weights='imagenet', include_top=False).layers)\n",
    "\n",
    "# last conv for having only one inbound node\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode=\"same\", name=\"CAM\"))\n",
    "model.add(GlobalAveragePooling2D(name=\"GAP\"))\n",
    "model.add(Dense(dataset_loader.nb_classes, activation='softmax', name='W'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "for i in range(0, epochs):\n",
    "    model.fit(x_train, y_train, batch_size=10, epochs=1, verbose=0)\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Loaded all imgs for test. Done! Next call will load train data\n",
      "DATASET LOADER] Loading completed!\n",
      "(1, 256, 256, 3)\n",
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1920930376163597e-07, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, x_test, y_test = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, dataset_loader.nb_classes)\n",
    "model.evaluate(x_test, y_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP TWO -> Define a k.function like generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process input\n",
    "input_img = x_train[2]\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbound (?, ?, ?, 512)\n"
     ]
    }
   ],
   "source": [
    "#Verify layer output \n",
    "print('inbound', model.get_layer('CAM').output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_outputs_generator(model, layer_name):\n",
    "    \"\"\"\n",
    "    Gets the output generator of a specific layer of the model.\n",
    "\n",
    "    :param model: The model\n",
    "    :param layer_name: The layer's name\n",
    "    :return: the output generator (a function)\n",
    "    \"\"\"\n",
    "    layer_model = Model(\n",
    "        input=model.input,\n",
    "        output=model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "    return layer_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[      0.           18852.58398438   30362.08203125 ...,       0.\n",
      "     56452.28515625   49098.98828125]\n",
      "  [      0.           21436.26367188   48549.01953125 ...,       0.\n",
      "     63323.1875       75877.2734375 ]\n",
      "  [      0.           22492.203125     56696.0546875  ...,       0.\n",
      "     62033.2578125    78869.78125   ]\n",
      "  ..., \n",
      "  [      0.           24158.08984375   57967.80078125 ...,       0.\n",
      "     66420.0625       80709.9921875 ]\n",
      "  [      0.           21514.79101562   54968.203125   ...,       0.\n",
      "     58024.765625     74239.8984375 ]\n",
      "  [      0.            6434.46142578   37318.50390625 ...,       0.\n",
      "     24003.98242188   37037.62890625]]\n",
      "\n",
      " [[      0.           45966.1953125    49511.90625    ...,       0.\n",
      "     61229.2578125    73452.515625  ]\n",
      "  [      0.           62642.75         87629.953125   ...,       0.\n",
      "     84852.1015625   108193.359375  ]\n",
      "  [      0.           65508.828125    101915.9921875  ...,       0.\n",
      "     85742.7421875   109334.5234375 ]\n",
      "  ..., \n",
      "  [      0.           67543.3203125   100567.96875    ...,       0.\n",
      "     88117.96875     111437.0859375 ]\n",
      "  [      0.           66396.484375     98621.421875   ...,       0.\n",
      "     88979.765625    104541.7421875 ]\n",
      "  [      0.           32167.00976562   75816.1640625  ...,       0.\n",
      "     60436.62109375   50222.19921875]]\n",
      "\n",
      " [[      0.           48833.96875      56292.00390625 ...,       0.\n",
      "     63042.0703125    74568.5390625 ]\n",
      "  [      0.           67987.53125      99439.8359375  ...,       0.\n",
      "     93410.1484375   112709.875     ]\n",
      "  [      0.           72566.4375      115626.453125   ...,       0.\n",
      "     96266.265625    113382.453125  ]\n",
      "  ..., \n",
      "  [      0.           75541.7890625   110635.90625    ...,       0.\n",
      "     91644.0625      113738.984375  ]\n",
      "  [      0.           77656.3671875   111568.3046875  ...,       0.\n",
      "     95339.453125    109492.625     ]\n",
      "  [      0.           40408.46484375   90465.7890625  ...,       0.\n",
      "     75268.875        52504.72265625]]\n",
      "\n",
      " ..., \n",
      " [[      0.           50116.37109375   56217.50390625 ...,       0.\n",
      "     59280.5078125    72862.4453125 ]\n",
      "  [      0.           72007.34375     100740.453125   ...,       0.\n",
      "     95041.8046875   112783.359375  ]\n",
      "  [      0.           81311.609375    118399.953125   ...,       0.\n",
      "    100811.90625     116097.7578125 ]\n",
      "  ..., \n",
      "  [      0.           80178.6875      113491.859375   ...,       0.\n",
      "     93528.7890625   110059.6328125 ]\n",
      "  [      0.           73084.2421875   105630.296875   ...,       0.\n",
      "     88370.9375       97129.1875    ]\n",
      "  [      0.           40504.32421875   83764.8046875  ...,       0.\n",
      "     71845.3828125    47611.47265625]]\n",
      "\n",
      " [[      0.           49804.84375      46240.92578125 ...,       0.\n",
      "     42973.875        59609.35546875]\n",
      "  [      0.           73519.90625      86406.5859375  ...,       0.\n",
      "     81147.609375     93439.828125  ]\n",
      "  [      0.           85100.296875    102106.90625    ...,       0.\n",
      "     90611.671875     96487.890625  ]\n",
      "  ..., \n",
      "  [      0.           82252.65625      98829.6640625  ...,       0.\n",
      "     87351.6328125    89679.6015625 ]\n",
      "  [      0.           71924.2578125    91325.78125    ...,       0.\n",
      "     82931.4765625    76394.8359375 ]\n",
      "  [      0.           41515.1328125    71017.8828125  ...,       0.\n",
      "     69066.765625     35925.0078125 ]]\n",
      "\n",
      " [[      0.           33956.31640625   19826.88085938 ...,       0.\n",
      "      7918.94140625   28269.82226562]\n",
      "  [      0.           56954.5546875    48246.921875   ...,       0.\n",
      "     40453.94921875   44108.33984375]\n",
      "  [      0.           66310.328125     58953.57421875 ...,       0.\n",
      "     48463.26171875   45072.94140625]\n",
      "  ..., \n",
      "  [      0.           64150.4140625    62042.17578125 ...,       0.\n",
      "     52161.6015625    41748.11328125]\n",
      "  [      0.           55086.91015625   58690.3125     ...,       0.\n",
      "     52956.8125       35444.2578125 ]\n",
      "  [      0.           33403.2734375    46759.51171875 ...,       0.\n",
      "     49391.3515625    16443.10351562]]]\n"
     ]
    }
   ],
   "source": [
    "print(layer_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer output shape (8, 8, 512)\n",
      "image shape (8, 8)\n",
      "number of filters: 512\n"
     ]
    }
   ],
   "source": [
    "#Grab the output of the layer:\n",
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)[0]\n",
    "print('layer output shape',layer_outputs.shape)\n",
    "img = layer_outputs[:, :, 0]\n",
    "print('image shape', img.shape)\n",
    "print('number of filters:', layer_outputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0fa3cad908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwKXG/gsPb1eZYQyaoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0fa3d264a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP layer shape (?, 512)\n",
      "layer w shape (2,)\n",
      "layer w shape[0] (512, 2)\n",
      "layer w[0] [[-0.08433722 -0.09633899]\n",
      " [-0.08749217  0.05524742]\n",
      " [-0.02333056 -0.0129181 ]\n",
      " ..., \n",
      " [ 0.10281374 -0.06855568]\n",
      " [ 0.00972111  0.08224002]\n",
      " [-0.10281602  0.09416955]]\n"
     ]
    }
   ],
   "source": [
    "print('GAP layer shape', model.get_layer('GAP').output.shape)\n",
    "print('layer w shape', np.asarray(model.get_layer(\"W\").get_weights()).shape)\n",
    "print('layer w shape[0]', model.get_layer(\"W\").get_weights()[0].shape)\n",
    "print('layer w[0]', model.get_layer(\"W\").get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So as we see here the weights that we need are as model.get_layer(\"W\").get_weights()[0][k_kernel][class_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reduce_opacity(im, opacity):\n",
    "    \"\"\"\n",
    "    Returns an image with reduced opacity.\n",
    "    Taken from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/362879\n",
    "    \"\"\"\n",
    "    assert 0 <= opacity <= 1\n",
    "    if im.mode != 'RGBA':\n",
    "        im = im.convert('RGBA')\n",
    "    else:\n",
    "        im = im.copy()\n",
    "    alpha = im.split()[3]\n",
    "    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n",
    "    im.putalpha(alpha)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def heatmap_generate(input_img, model, class_to_predict, layer_name, image_name=None):\n",
    "   \n",
    "    output_generator = get_outputs_generator(model, layer_name)\n",
    "    layer_outputs = output_generator(np.expand_dims(input_img, axis=0))[0]\n",
    "    heatmap = Image.new(\"RGBA\", (224, 224), color=0)\n",
    "    # Normalize input on weights\n",
    "    w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "\n",
    "    for z in range(0, layer_outputs.shape[2]): # Iterate through the number of kernels\n",
    "        img = layer_outputs[:, :, z]\n",
    "\n",
    "        deprocessed = scipy.misc.toimage(cv2.resize(img, (224, 224))).convert(\"RGBA\")\n",
    "        datas = deprocessed.getdata()\n",
    "        new_data = []\n",
    "        # remove back background -> ASK FOR VALIDATION\n",
    "        for item in datas:\n",
    "            if item[0] < 16 and item[1] < 16 and item[2] < 16:\n",
    "                new_data.append((0, 0, 0, 0))\n",
    "            else:\n",
    "                new_data.append(item)\n",
    "        deprocessed.putdata(new_data)\n",
    "        \n",
    "        deprocessed = reduce_opacity(deprocessed, w[z][class_to_predict])\n",
    "        heatmap.paste(deprocessed, (0, 0), deprocessed)\n",
    "    # heatmap = image.img_to_array(ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\"))\n",
    "    # ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\").save(\"TMP.png\", \"PNG\")\n",
    "    heatmap.save(\"TMP.png\", \"PNG\")\n",
    "    heatmap = cv2.imread(\"TMP.png\", cv2.CV_8UC3)  # FIXME: remove tmp file\n",
    "    \n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * np.asarray(heatmap)), cv2.COLORMAP_JET)\n",
    "    heatmap_colored[np.where(heatmap <= 0.2)] = 0\n",
    "\n",
    "    if image_name is not None:\n",
    "        heatmap_colored = cv2.putText(heatmap_colored, image_name, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0),\n",
    "                                      2)\n",
    "    return Image.fromarray(cv2.resize(heatmap_colored, (224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "input_img = x_train[2]\n",
    "img = heatmap_generate(input_img, model, 0, 'CAM', image_name='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12316665  0.04063714]\n",
      " [ 0.1085605   0.74297124]\n",
      " [ 0.4056029   0.427145  ]\n",
      " ..., \n",
      " [ 0.98960018  0.1693635 ]\n",
      " [ 0.55861884  0.86803401]\n",
      " [ 0.03761727  0.92330623]]\n",
      "[ 0.12316665  0.04063714]\n",
      "0.123167\n"
     ]
    }
   ],
   "source": [
    "w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "print(w)\n",
    "print(w[0])\n",
    "print(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
