{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from img_loader import DatasetLoader\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.misc\n",
    "from PIL import ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP ONE -> Create a CAM compatible VGG16 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Discovering dataset...\n",
      "DATASET LOADER] \n",
      "2 classes found.\n",
      " 4 images found.\n",
      "DATASET LOADER] Shuffling order...\n",
      "DATASET LOADER] \n",
      "Ready for loading!\n",
      " 3 for training and 1 for testing\n",
      "DATASET LOADER] Loaded all imgs for training. Next call will load test data...\n",
      "DATASET LOADER] Loading completed!\n",
      "(3, 256, 256, 3)\n",
      "(3, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_loader = DatasetLoader('dataset_mini', 10000)\n",
    "_, x_train, y_train = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float64')\n",
    "\n",
    "x_train = preprocess_input(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, dataset_loader.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "CAM (Conv2D)                 (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "W (Dense)                    (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 17,075,522.0\n",
      "Trainable params: 17,075,522.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"CAM\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(applications.VGG16(weights='imagenet', include_top=False).layers)\n",
    "\n",
    "# last conv for having only one inbound node\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode=\"same\", name=\"CAM\"))\n",
    "model.add(GlobalAveragePooling2D(name=\"GAP\"))\n",
    "model.add(Dense(dataset_loader.nb_classes, activation='softmax', name='W'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "for i in range(0, epochs):\n",
    "    model.fit(x_train, y_train, batch_size=10, epochs=1, verbose=0)\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Loaded all imgs for test. Done! Next call will load train data\n",
      "DATASET LOADER] Loading completed!\n",
      "(1, 256, 256, 3)\n",
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.118095397949219, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, x_test, y_test = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, dataset_loader.nb_classes)\n",
    "model.evaluate(x_test, y_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STEP TWO -> Define a k.function like generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process input\n",
    "input_img = x_train[2]\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbound (?, ?, ?, 512)\n"
     ]
    }
   ],
   "source": [
    "#Verify layer output \n",
    "print('inbound', model.get_layer('CAM').output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_outputs_generator(model, layer_name):\n",
    "    \"\"\"\n",
    "    Gets the output generator of a specific layer of the model.\n",
    "\n",
    "    :param model: The model\n",
    "    :param layer_name: The layer's name\n",
    "    :return: the output generator (a function)\n",
    "    \"\"\"\n",
    "    layer_model = Model(\n",
    "        input=model.input,\n",
    "        output=model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "    return layer_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 129188.765625         0.               0.         ...,       0.\n",
      "    61232.40234375       0.        ]\n",
      " [ 139999.5625           0.               0.         ...,       0.\n",
      "   211603.578125     84796.4453125 ]\n",
      " [ 136389.953125         0.               0.         ...,       0.\n",
      "   258888.171875    110040.890625  ]\n",
      " ..., \n",
      " [ 123336.6875           0.               0.         ...,       0.\n",
      "   260843.265625    114633.5078125 ]\n",
      " [ 102955.390625         0.               0.         ...,       0.\n",
      "   242876.9375      117945.5078125 ]\n",
      " [  48318.03125          0.               0.         ...,       0.\n",
      "   210414.421875    119010.5234375 ]]\n"
     ]
    }
   ],
   "source": [
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)\n",
    "print(layer_outputs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer output shape (8, 8, 512)\n",
      "image shape (8, 8)\n",
      "number of filters: 512\n"
     ]
    }
   ],
   "source": [
    "#Grab the output of the layer:\n",
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)[0]\n",
    "print('layer output shape',layer_outputs.shape)\n",
    "img = layer_outputs[:, :, 0]\n",
    "print('image shape', img.shape)\n",
    "print('number of filters:', layer_outputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9ded64bac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ded756ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP layer shape (?, 512)\n",
      "layer w shape (2,)\n",
      "layer w shape[0] (512, 2)\n",
      "layer w[0] [[-0.06854053  0.01418136]\n",
      " [ 0.06703734 -0.01170113]\n",
      " [ 0.01395767 -0.05648329]\n",
      " ..., \n",
      " [ 0.09105442  0.02528536]\n",
      " [-0.0962165  -0.03545291]\n",
      " [ 0.00345529  0.08175828]]\n",
      "layer w shape[1] (2,)\n",
      "layer w[1] [-0.00266826  0.00266826]\n"
     ]
    }
   ],
   "source": [
    "print('GAP layer shape', model.get_layer('GAP').output.shape)\n",
    "print('layer w shape', np.asarray(model.get_layer(\"W\").get_weights()).shape)\n",
    "print('layer w shape[0]', model.get_layer(\"W\").get_weights()[0].shape)\n",
    "print('layer w[0]', model.get_layer(\"W\").get_weights()[0])\n",
    "print('layer w shape[1]', model.get_layer(\"W\").get_weights()[1].shape)\n",
    "print('layer w[1]', model.get_layer(\"W\").get_weights()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So as we see here the weights that we need are as model.get_layer(\"W\").get_weights()[0][k_kernel][class_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reduce_opacity(im, opacity):\n",
    "    \"\"\"\n",
    "    Returns an image with reduced opacity.\n",
    "    Taken from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/362879\n",
    "    \"\"\"\n",
    "    assert 0 <= opacity <= 1\n",
    "    if im.mode != 'RGBA':\n",
    "        im = im.convert('RGBA')\n",
    "    else:\n",
    "        im = im.copy()\n",
    "    alpha = im.split()[3]\n",
    "    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n",
    "    im.putalpha(alpha)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def heatmap_generate(input_img, model, class_to_predict, layer_name, image_name=None):\n",
    "   \n",
    "    output_generator = get_outputs_generator(model, layer_name)\n",
    "    layer_outputs = output_generator(np.expand_dims(input_img, axis=0))[0]\n",
    "    heatmap = Image.new(\"RGBA\", (224, 224), color=0)\n",
    "    # Normalize input on weights\n",
    "    w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "\n",
    "    for z in range(0, layer_outputs.shape[2]): # Iterate through the number of kernels\n",
    "        img = layer_outputs[:, :, z]\n",
    "\n",
    "        deprocessed = scipy.misc.toimage(cv2.resize(img, (224, 224))).convert(\"RGBA\")\n",
    "        datas = deprocessed.getdata()\n",
    "        new_data = []\n",
    "        # remove back background\n",
    "        for item in datas:\n",
    "            if item[0] < 16 and item[1] < 16 and item[2] < 16:\n",
    "                new_data.append((0, 0, 0, 0))\n",
    "            else:\n",
    "                new_data.append(item)\n",
    "        deprocessed.putdata(new_data)\n",
    "        deprocessed = reduce_opacity(deprocessed, w[z][class_to_predict])\n",
    "        heatmap.paste(deprocessed, (0, 0), deprocessed)\n",
    "    # heatmap = image.img_to_array(ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\"))\n",
    "    ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\").save(\"TMP.png\", \"PNG\")\n",
    "    heatmap = cv2.imread(\"TMP.png\", cv2.CV_8UC3)  # FIXME: remove tmp file\n",
    "    \n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * np.asarray(heatmap)), cv2.COLORMAP_JET)\n",
    "    heatmap_colored[np.where(heatmap <= 0.2)] = 0\n",
    "\n",
    "    if image_name is not None:\n",
    "        heatmap_colored = cv2.putText(heatmap_colored, image_name, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0),\n",
    "                                      2)\n",
    "    return Image.fromarray(cv2.resize(heatmap_colored, (224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "input_img = x_train[2]\n",
    "img = heatmap_generate(input_img, model, 0, 'CAM', image_name='test')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19481021  0.55294317]\n",
      " [ 0.82419109  0.43302551]\n",
      " [ 0.57778412  0.22554266]\n",
      " ..., \n",
      " [ 0.93568343  0.60438973]\n",
      " [ 0.06633255  0.32297975]\n",
      " [ 0.52902985  0.86603767]]\n",
      "[ 0.19481021  0.55294317]\n",
      "0.19481\n"
     ]
    }
   ],
   "source": [
    "w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "print(w)\n",
    "print(w[0])\n",
    "print(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
