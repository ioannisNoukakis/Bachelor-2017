{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from img_loader import DatasetLoader\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.misc\n",
    "from PIL import ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP ONE -> Create a CAM compatible VGG16 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Discovering dataset...\n",
      "DATASET LOADER] \n",
      "2 classes found.\n",
      " 4 images found.\n",
      "DATASET LOADER] Shuffling order...\n",
      "DATASET LOADER] \n",
      "Ready for loading!\n",
      " 3 for training and 1 for testing\n",
      "DATASET LOADER] Loaded all imgs for training. Next call will load test data...\n",
      "DATASET LOADER] Loading completed!\n",
      "(3, 256, 256, 3)\n",
      "(3, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_loader = DatasetLoader('dataset_mini', 10000)\n",
    "_, x_train, y_train = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float64')\n",
    "\n",
    "x_train = preprocess_input(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, dataset_loader.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "CAM (Conv2D)                 (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "W (Dense)                    (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 17,075,522.0\n",
      "Trainable params: 17,075,522.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"CAM\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(applications.VGG16(weights='imagenet', include_top=False).layers)\n",
    "\n",
    "# last conv for having only one inbound node\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode=\"same\", name=\"CAM\"))\n",
    "model.add(GlobalAveragePooling2D(name=\"GAP\"))\n",
    "model.add(Dense(dataset_loader.nb_classes, activation='softmax', name='W'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "for i in range(0, epochs):\n",
    "    model.fit(x_train, y_train, batch_size=10, epochs=1, verbose=0)\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADER] Loaded all imgs for test. Done! Next call will load train data\n",
      "DATASET LOADER] Loading completed!\n",
      "(1, 256, 256, 3)\n",
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.118095397949219, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, x_test, y_test = dataset_loader.load_dataset()\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, dataset_loader.nb_classes)\n",
    "model.evaluate(x_test, y_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP TWO -> Define a k.function like generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process input\n",
    "input_img = x_train[2]\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inbound (?, ?, ?, 512)\n"
     ]
    }
   ],
   "source": [
    "#Verify layer output \n",
    "print('inbound', model.get_layer('CAM').output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outputs_generator(model, layer_name):\n",
    "    \"\"\"\n",
    "    Gets the output generator of a specific layer of the model.\n",
    "\n",
    "    :param model: The model\n",
    "    :param layer_name: The layer's name\n",
    "    :return: the output generator (a function)\n",
    "    \"\"\"\n",
    "    layer_model = Model(\n",
    "        input=model.input,\n",
    "        output=model.get_layer(layer_name).output\n",
    "    )\n",
    "\n",
    "    return layer_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[      0.               0.               0.         ...,       0.\n",
      "      90555.59375          0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     165461.921875         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     188721.984375         0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     191059.828125         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     171309.0625           0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     117734.6015625        0.        ]]\n",
      "\n",
      "  [[      0.               0.               0.         ...,       0.\n",
      "     109588.0078125        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     201590.9375           0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     226545.125            0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     228773.90625          0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     207966.390625         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     150526.140625         0.        ]]\n",
      "\n",
      "  [[      0.               0.               0.         ...,       0.\n",
      "     109759.3359375        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     203797.4375           0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     229754.359375         0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     229872.078125         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     212505.5625           0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     160016.90625          0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[      0.               0.               0.         ...,       0.\n",
      "     103121.9453125        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     196843.46875          0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     219266.71875          0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     170787.890625         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     154353.171875         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     121886.8046875        0.        ]]\n",
      "\n",
      "  [[      0.               0.               0.         ...,       0.\n",
      "      94425.3203125        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     181363.40625          0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     195727.53125          0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     124748.1328125        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "     111792.328125         0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      90086.8359375        0.        ]]\n",
      "\n",
      "  [[      0.               0.               0.         ...,       0.\n",
      "      19417.5              0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      47584.73046875       0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      53665.89453125       0.        ]\n",
      "   ..., \n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      31816.43164062       0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      29546.0390625        0.        ]\n",
      "   [      0.               0.               0.         ...,       0.\n",
      "      29673.20703125       0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer output shape (8, 8, 512)\n",
      "image shape (8, 8)\n",
      "number of filters: 512\n"
     ]
    }
   ],
   "source": [
    "#Grab the output of the layer:\n",
    "output_generator = get_outputs_generator(model, 'CAM')\n",
    "layer_outputs = output_generator(input_img)[0]\n",
    "print('layer output shape',layer_outputs.shape)\n",
    "img = layer_outputs[:, :, 0]\n",
    "print('image shape', img.shape)\n",
    "print('number of filters:', layer_outputs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f294c285be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACcBJREFUeJzt3d+rZXUZx/H3p/HH5I8UykIcSS9EkCCNwQhDSCk0xbro\nQiEhCeZKUQpCu+sfCLsIIUZN0JQyBRFTrIwKypwZp9IZDRsMZ7BGidCEHH88XZw9McrEWWf2WrP3\neXi/4DBn77PZPJvhPWvtdfZ8v6kqJPX0gUUPIGk6Bi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBS\nY8dM8aTH5fjayIlTPLUk4D+8wYF6M6s9bpLAN3Iin86lUzy1JODJ+sWgx3mKLjVm4FJjBi41ZuBS\nYwYuNWbgUmMGLjVm4FJjgwJPclmS55O8kOTmqYeSNI5VA0+yAfg+cDlwHnBNkvOmHkzS/IYcwS8E\nXqiqPVV1ALgP+NK0Y0kaw5DAzwBeOuT23tl9kpbcaP/ZJMkWYAvARk4Y62klzWHIEXwfcOYhtzfN\n7nuPqvpBVW2uqs3HcvxY80maw5DAnwLOSXJ2kuOAq4GHph1L0hhWPUWvqreTXA88BmwA7qiqZyef\nTNLcBr0Hr6pHgEcmnkXSyPwkm9SYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiB\nS40ZuNSYgUuNGbjUmIFLjRm41JiBS40N2dnkjiT7kzxzNAaSNJ4hR/AfApdNPIekCawaeFX9Gvjn\nUZhF0sh8Dy415tZFUmOjHcHdukhaPp6iS40N+TXZvcDvgHOT7E3y9enHkjSGIXuTXXM0BpE0Pk/R\npcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMCl\nxgxcaszApcaGLLp4ZpInkuxK8mySG4/GYJLmN2Tjg7eBb1bVjiQnA9uTPF5VuyaeTdKchuxN9nJV\n7Zh9/zqwGzhj6sEkzW9NWxclOQu4AHjyMD9z6yJpyQy+yJbkJOCnwE1V9dr7f+7WRdLyGRR4kmNZ\nifueqnpg2pEkjWXIVfQAtwO7q+q7048kaSxDjuAXAdcClyTZOfv64sRzSRrBkL3JfgvkKMwiaWR+\nkk1qzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYM\nXGrMwKXGhiy6uDHJH5L8cbZ10XeOxmCS5jdk44M3gUuq6t+z5ZN/m+RnVfX7iWeTNKchiy4W8O/Z\nzWNnXzXlUJLGMXTjgw1JdgL7gcer6rBbFyXZlmTbW7w59pySjsCgwKvqnao6H9gEXJjkE4d5jFsX\nSUtmTVfRq+pfwBPAZdOMI2lMQ66in5bk1Nn3HwQ+Dzw39WCS5jfkKvrpwF1JNrDyD8KPq+rhaceS\nNIYhV9H/xMqe4JLWGT/JJjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMG\nLjVm4FJjBi41ZuBSYwYuNWbgUmODA5+tjf50Etdjk9aJtRzBbwR2TzWIpPEN3dlkE3AFsHXacSSN\naegR/FbgW8C7E84iaWRDNj64EthfVdtXeZx7k0lLZsgR/CLgqiQvAvcBlyS5+/0Pcm8yafmsGnhV\n3VJVm6rqLOBq4JdV9dXJJ5M0N38PLjU2ZG+y/6mqXwG/mmQSSaPzCC41ZuBSYwYuNWbgUmMGLjVm\n4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjg5Zsmq2o+jrwDvB2\nVW2ecihJ41jLmmyfq6pXJ5tE0ug8RZcaGxp4AT9Psj3JlikHkjSeoafon62qfUk+Cjye5Lmq+vWh\nD5iFvwVgIyeMPKakIzHoCF5V+2Z/7gceBC48zGPcukhaMkM2HzwxyckHvwe+ADwz9WCS5jfkFP1j\nwINJDj7+R1X16KRTSRrFqoFX1R7gk0dhFkkj89dkUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm\n4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNTYo8CSnJrk/yXNJdif5zNSDSZrf0HXR\nvwc8WlVfSXIcuPC5tB6sGniSU4CLga8BVNUB4MC0Y0kaw5BT9LOBV4A7kzydZOtsfXRJS25I4McA\nnwJuq6oLgDeAm9//oCRbkmxLsu0t3hx5TElHYkjge4G9VfXk7Pb9rAT/Hm5dJC2fVQOvqr8DLyU5\nd3bXpcCuSaeSNIqhV9FvAO6ZXUHfA1w33UiSxjIo8KraCWyeeBZJI/OTbFJjBi41ZuBSYwYuNWbg\nUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjqwae5Nwk\nOw/5ei3JTUdjOEnzWXXRxap6HjgfIMkGYB/w4MRzSRrBWk/RLwX+WlV/m2IYSeMaui76QVcD9x7u\nB0m2AFsANrr5qLQUBh/BZ5seXAX85HA/d+siafms5RT9cmBHVf1jqmEkjWstgV/D/zk9l7ScBgU+\n2w/888AD044jaUxD9yZ7A/jwxLNIGpmfZJMaM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpsVTV+E+a\nvAKs9b+UfgR4dfRhlkPX1+brWpyPV9Vpqz1oksCPRJJtVbV50XNMoetr83UtP0/RpcYMXGpsmQL/\nwaIHmFDX1+brWnJL8x5c0viW6QguaWRLEXiSy5I8n+SFJDcvep4xJDkzyRNJdiV5NsmNi55pTEk2\nJHk6ycOLnmVMSU5Ncn+S55LsTvKZRc80j4Wfos/WWv8LKyvG7AWeAq6pql0LHWxOSU4HTq+qHUlO\nBrYDX17vr+ugJN8ANgMfqqorFz3PWJLcBfymqrbOFho9oar+tei5jtQyHMEvBF6oqj1VdQC4D/jS\ngmeaW1W9XFU7Zt+/DuwGzljsVONIsgm4Ati66FnGlOQU4GLgdoCqOrCe44blCPwM4KVDbu+lSQgH\nJTkLuAB4crGTjOZW4FvAu4seZGRnA68Ad87efmydrUe4bi1D4K0lOQn4KXBTVb226HnmleRKYH9V\nbV/0LBM4BvgUcFtVXQC8Aazra0LLEPg+4MxDbm+a3bfuJTmWlbjvqaouK9JeBFyV5EVW3k5dkuTu\nxY40mr3A3qo6eKZ1PyvBr1vLEPhTwDlJzp5d1LgaeGjBM80tSVh5L7e7qr676HnGUlW3VNWmqjqL\nlb+rX1bVVxc81iiq6u/AS0nOnd11KbCuL4qudW+y0VXV20muBx4DNgB3VNWzCx5rDBcB1wJ/TrJz\ndt+3q+qRBc6k1d0A3DM72OwBrlvwPHNZ+K/JJE1nGU7RJU3EwKXGDFxqzMClxgxcaszApcYMXGrM\nwKXG/gvgr1ebpfUf7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f294c361f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP layer shape (?, 512)\n",
      "layer w shape (2,)\n",
      "layer w shape[0] (512, 2)\n",
      "layer w[0] [[-0.01830806 -0.02314503]\n",
      " [-0.01723217  0.10384279]\n",
      " [-0.05846901  0.04050887]\n",
      " ..., \n",
      " [-0.0504413   0.03347859]\n",
      " [-0.06111011 -0.10115343]\n",
      " [ 0.00984336  0.06877398]]\n",
      "layer w shape[1] (2,)\n",
      "layer w[1] [ 0.0029709 -0.0029709]\n"
     ]
    }
   ],
   "source": [
    "print('GAP layer shape', model.get_layer('GAP').output.shape)\n",
    "print('layer w shape', np.asarray(model.get_layer(\"W\").get_weights()).shape)\n",
    "print('layer w shape[0]', model.get_layer(\"W\").get_weights()[0].shape)\n",
    "print('layer w[0]', model.get_layer(\"W\").get_weights()[0])\n",
    "print('layer w shape[1]', model.get_layer(\"W\").get_weights()[1].shape)\n",
    "print('layer w[1]', model.get_layer(\"W\").get_weights()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we see here the weights that we need are as model.get_layer(\"W\").get_weights()[0][k_kernel][class_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_opacity(im, opacity):\n",
    "    \"\"\"\n",
    "    Returns an image with reduced opacity.\n",
    "    Taken from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/362879\n",
    "    \"\"\"\n",
    "    assert 0 <= opacity <= 1\n",
    "    if im.mode != 'RGBA':\n",
    "        im = im.convert('RGBA')\n",
    "    else:\n",
    "        im = im.copy()\n",
    "    alpha = im.split()[3]\n",
    "    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n",
    "    im.putalpha(alpha)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heatmap_generate(input_img, model, class_to_predict, layer_name, image_name=None):\n",
    "   \n",
    "    output_generator = get_outputs_generator(model, layer_name)\n",
    "    layer_outputs = output_generator(np.expand_dims(input_img, axis=0))[0]\n",
    "    heatmap = Image.new(\"RGBA\", (224, 224), color=0)\n",
    "    # Normalize input on weights\n",
    "    w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "\n",
    "    for z in range(0, layer_outputs.shape[2]): # Iterate through the number of kernels\n",
    "        img = layer_outputs[:, :, z]\n",
    "\n",
    "        deprocessed = scipy.misc.toimage(cv2.resize(img, (224, 224))).convert(\"RGBA\")\n",
    "        datas = deprocessed.getdata()\n",
    "        new_data = []\n",
    "        # remove back background\n",
    "        for item in datas:\n",
    "            if item[0] < 16 and item[1] < 16 and item[2] < 16:\n",
    "                new_data.append((0, 0, 0, 0))\n",
    "            else:\n",
    "                new_data.append(item)\n",
    "        deprocessed.putdata(new_data)\n",
    "        deprocessed = reduce_opacity(deprocessed, w[z][class_to_predict])\n",
    "        heatmap.paste(deprocessed, (0, 0), deprocessed)\n",
    "    # heatmap = image.img_to_array(ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\"))\n",
    "    # ImageOps.invert(heatmap.convert(\"RGB\")).convert(\"RGBA\").save(\"TMP.png\", \"PNG\")\n",
    "    heatmap.save(\"TMP.png\", \"PNG\")\n",
    "    heatmap = cv2.imread(\"TMP.png\", cv2.CV_8UC3)  # FIXME: remove tmp file\n",
    "    \n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * np.asarray(heatmap)), cv2.COLORMAP_JET)\n",
    "    heatmap_colored[np.where(heatmap <= 0.2)] = 0\n",
    "\n",
    "    if image_name is not None:\n",
    "        heatmap_colored = cv2.putText(heatmap_colored, image_name, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0),\n",
    "                                      2)\n",
    "    return Image.fromarray(cv2.resize(heatmap_colored, (224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"CA...)`\n"
     ]
    }
   ],
   "source": [
    "input_img = x_train[2]\n",
    "img = heatmap_generate(input_img, model, 0, 'CAM', image_name='test')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40850377  0.40688425]\n",
      " [ 0.41344133  0.9950999 ]\n",
      " [ 0.22419217  0.70173317]\n",
      " ..., \n",
      " [ 0.26103395  0.66916847]\n",
      " [ 0.21207133  0.04554445]\n",
      " [ 0.5376997   0.83265901]]\n",
      "[ 0.40850377  0.40688425]\n",
      "0.408504\n"
     ]
    }
   ],
   "source": [
    "w = MinMaxScaler((0.0, 1.0)).fit_transform(model.get_layer(\"W\").get_weights()[0])\n",
    "print(w)\n",
    "print(w[0])\n",
    "print(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
