STEP one build VGG16 FT and train it
-> very bad results [[14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528], [14.544812317192108, 0.097609762795711347], [14.532413921921263, 0.098378984400218528]]

STEP Two: train VGG16 with classic architecture and then load, remove fully connected
add GAP and do more training then draw CAMs.

But the fully connected does even worse! [VGG16_FT] [[15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445], [15.826328813606459, 0.018101810450756092], [15.823104876520061, 0.018301830455736825], [15.790865470366617, 0.020302030505544126], [15.868240028157784, 0.015501550386006599], [15.853864450923732, 0.016393442867232152], [15.806985176781533, 0.019301930480640474], [15.789246738789933, 0.020402459799410445]]

HEre are the finals results over 5 epochs
[[0.11920067143452988, 0.96319631371859105], [0.10552861226166615, 0.96534376187055315], [0.11028753402932762, 0.96679667437454497], [0.10554082990884833, 0.96646170578834534], [0.047632323303149232, 0.98609860696391061], [0.04933760498798271, 0.98462828079237497], [0.043999131675324411, 0.98509850683468847], [0.037145160485338787, 0.9863051955029577], [0.037988017091219108, 0.98849884750056427], [0.040775122291613924, 0.98742313858781727]]

ANd here we saved the model rather than its weights.
[VGG16_FT] [[0.15059231647470822, 0.955295523126932], [0.17338450570383082, 0.94214644480044785], [0.10067342008284623, 0.96909690500557544], [0.11132651846616431, 0.96310787620059335], [0.04224727773656075, 0.98509850689429901], [0.044259932781494989, 0.9851872524847326], [0.054093553566255996, 0.98279827662093222], [0.065893511065185248, 0.97708216431155559], [0.11487178353692709, 0.9666966642304794], [0.13166247157077818, 0.96366684765972987]]
[VGG16_FT]

AND HERE IS THE RANDOM TRAINING
[VGG16_FT] [[0.2953591924101967, 0.90799079443028075], [0.31047118199232759, 0.90441586887656544], [0.12510496453532971, 0.95869586426969267], [0.14721509595741267, 0.9569591893171584], [0.13716532322187841, 0.95389538307716426], [0.16159871497299066, 0.95136947405944661], [0.075858183982010122, 0.97469746484698294], [0.1014901455537167, 0.967300162227411], [0.072395921340482061, 0.97669766588036522], [0.096651912232993131, 0.97121296294112658]]

AND HERE IS THE ART TRAINING
[VGG16_FT] [[0.24890181820709525, 0.92259225310987447], [0.22573917906239677, 0.9264952426119315], [0.13822573937056584, 0.95459545366834886], [0.12620074247142957, 0.95500278862712773], [0.08985493356327455, 0.97309730528402194], [0.089184957334495704, 0.97205142137923006], [0.11366475248030242, 0.96249624390234434], [0.109190725485662, 0.96450530533153567], [0.10535136753811028, 0.97079707447415964], [0.099246639476883308, 0.96869759119176679]]
[VGG16_FT]

STEP 2.5 VALIDATE CAMS!

STEP tree with all 4 background and their combinaisons

STEP four bias metrics with mohanty

STEP 5 analyse results
